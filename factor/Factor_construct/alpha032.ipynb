{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a86776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e4b3e7",
   "metadata": {},
   "source": [
    "### 因子构造样例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897b940d",
   "metadata": {},
   "source": [
    "#### 预先读取merge_daily_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8bdf229",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_daily_info = pd.read_parquet(r'/Users/xuyanye/Desktop/quant_mm/factor/data/merge_daily_info.parquet')\n",
    "merge_daily_info['TradingDate'] = pd.to_datetime(merge_daily_info['TradingDate'])\n",
    "merge_daily_info = merge_daily_info.drop_duplicates(subset=['Stkcd','TradingDate'])\n",
    "TRD_Dalyr = pd.read_parquet(r'/Users/xuyanye/Desktop/quant_mm/factor/data/TRD_Dalyr.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18295fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Stkcd', 'TradingDate', 'Opnprc', 'Hiprc', 'Loprc', 'Clsprc',\n",
       "       'Dnshrtrd', 'Dnvaltrd', 'Dsmvosd', 'Dsmvtll', 'Dretwd', 'Dretnd',\n",
       "       'Adjprcwd', 'Adjprcnd', 'Markettype', 'Capchgdt', 'Trdsta',\n",
       "       'Ahshrtrd_D', 'Ahvaltrd_D', 'PreClosePrice', 'ChangeRatio', 'LimitDown',\n",
       "       'LimitUp', 'LimitStatus'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRD_Dalyr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30485aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TradingDate', 'Stkcd', 'Dnvaltrd', 'Dnshrtrd', 'Clsprc'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据提取与合并\n",
    "Dnvaltrd = TRD_Dalyr[['TradingDate','Stkcd','Dnvaltrd']]\n",
    "Dnshrtrd = TRD_Dalyr[['TradingDate','Stkcd','Dnshrtrd']]\n",
    "Clsprc = TRD_Dalyr[['TradingDate','Stkcd','Clsprc']]\n",
    "calc_cvturn = pd.merge(Dnvaltrd,Dnshrtrd ,on=['TradingDate','Stkcd'],how='left')\n",
    "calc_cvturn = pd.merge(calc_cvturn,Clsprc ,on=['TradingDate','Stkcd'],how='left')\n",
    "calc_cvturn.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c4c8b",
   "metadata": {},
   "source": [
    "# alpha032"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57ce57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_FACTOR_NAME = \"alpha032\" \n",
    "ALPHA_SAVE_PATH_DIR = \"/Users/xuyanye/Desktop/quant mm/factor/alpha\"\n",
    "if not os.path.exists(ALPHA_SAVE_PATH_DIR):\n",
    "    os.makedirs(ALPHA_SAVE_PATH_DIR)\n",
    "# 定义最终因子在DataFrame中的列名，以及Parquet文件的基础名称\n",
    "# 这两部分必须一致，才能被您的回测代码正确识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42946890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/sy28sk9165s6btqff5dbsdmc0000gn/T/ipykernel_86674/3870154798.py:30: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  calc_factor_data['corr_vwap_delay_close_230'] = calc_factor_data.groupby('Stkcd').apply(\n",
      "/var/folders/6j/sy28sk9165s6btqff5dbsdmc0000gn/T/ipykernel_86674/3870154798.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  calc_factor_data['alpha_new_factor'].replace([float('inf'), float('-inf')], 0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# 假设 calc_factor_data 是原始数据\n",
    "calc_factor_data = calc_cvturn.copy()\n",
    "\n",
    "# 1. 确保数据按股票代码和交易日期排序\n",
    "calc_factor_data = calc_factor_data.sort_values(by=['Stkcd', 'TradingDate']).copy()\n",
    "\n",
    "# 2. 计算第一个主要部分：scale(((sum(close, 7) / 7) - close))\n",
    "# 计算过去7日的简单移动平均 (SMA) 即 (sum(close, 7) / 7)\n",
    "calc_factor_data['avg_close_7'] = calc_factor_data.groupby('Stkcd')['Clsprc'].rolling(window=7, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# 计算 (7日均线 - 当前日收盘价)\n",
    "calc_factor_data['avg_minus_current_close'] = calc_factor_data['avg_close_7'] - calc_factor_data['Clsprc']\n",
    "\n",
    "# scale操作：标准化 (Z-score scaling)，使得绝对值总和为1\n",
    "def scale(x):\n",
    "    total_abs = x.abs().sum()\n",
    "    return x / total_abs if total_abs != 0 else 0\n",
    "\n",
    "# 对第一部分进行scale\n",
    "calc_factor_data['scaled_avg_minus_current_close'] = calc_factor_data.groupby('TradingDate')['avg_minus_current_close'].transform(scale)\n",
    "\n",
    "# 3. 计算第二个主要部分：20 * scale(correlation(vwap, delay(close, 5), 230))\n",
    "# 计算VWAP (成交量加权平均价)\n",
    "calc_factor_data['vwap'] = calc_factor_data['Dnvaltrd'] / calc_factor_data['Dnshrtrd']\n",
    "\n",
    "# 获取延迟5个交易日的收盘价\n",
    "calc_factor_data['delay_close_5'] = calc_factor_data.groupby('Stkcd')['Clsprc'].shift(5)\n",
    "\n",
    "# 计算过去230个交易日VWAP与延迟5日收盘价的相关性\n",
    "calc_factor_data['corr_vwap_delay_close_230'] = calc_factor_data.groupby('Stkcd').apply(\n",
    "    lambda x: x['vwap'].rolling(window=230, min_periods=1).corr(x['delay_close_5'])\n",
    ").reset_index(level=0, drop=True)\n",
    "\n",
    "# 对相关性进行scale操作\n",
    "calc_factor_data['scaled_corr_vwap_delay_close_230'] = calc_factor_data.groupby('TradingDate')['corr_vwap_delay_close_230'].transform(scale)\n",
    "\n",
    "# 4. 计算最终因子：20 * scale(correlation(vwap, delay(close, 5), 230))\n",
    "calc_factor_data['weighted_scaled_corr'] = 20 * calc_factor_data['scaled_corr_vwap_delay_close_230']\n",
    "\n",
    "# 5. 将两部分相加，得到原始因子值\n",
    "calc_factor_data['raw_factor'] = calc_factor_data['scaled_avg_minus_current_close'] + calc_factor_data['weighted_scaled_corr']\n",
    "\n",
    "# 6. 对最终的原始因子值进行整体归一化 (Z-score scaling)\n",
    "calc_factor_data['alpha_new_factor'] = calc_factor_data.groupby('TradingDate')['raw_factor'].transform(\n",
    "    lambda x: (x - x.mean()) / x.std() if x.std() != 0 else 0\n",
    ")\n",
    "\n",
    "# 将 inf 和 -inf 替换为 0\n",
    "calc_factor_data['alpha_new_factor'].replace([float('inf'), float('-inf')], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11b13da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Stkcd TradingDate  alpha032\n",
      "6       1  1991-04-10  1.024810\n",
      "7       1  1991-04-12 -0.971897\n",
      "9       1  1991-04-16  0.879270\n",
      "10      1  1991-04-17 -1.366789\n",
      "11      1  1991-04-18 -1.607555\n"
     ]
    }
   ],
   "source": [
    "# 假设 merge_daily_info 是另一个包含 Stkcd 和 TradingDate 的 DataFrame\n",
    "# 将计算出的 Alpha08_Factor 合并到 merge_daily_info\n",
    "# 注意：如果 calc_cvturn 就是最终要用的 DataFrame，可能不需要这一步合并\n",
    "# 这里为了与用户提供的格式保持一致，假设有一个目标 DataFrame 'merge_daily_info'\n",
    "# 如果 calc_cvturn 本身就是最终结果，则可以跳过此合并步骤\n",
    "# 请根据实际情况调整 'merge_daily_info' 的定义\n",
    "try:\n",
    "    # 模拟 merge_daily_info 如果它不存在\n",
    "    if 'merge_daily_info' not in locals():\n",
    "        print(\"警告：'merge_daily_info' 未定义。为演示目的，将假设 merge_daily_info 等同于 calc_cvturn 的基础部分。\")\n",
    "        merge_daily_info = calc_cvturn[['Stkcd', 'TradingDate']].copy() # 只是一个示例\n",
    "\n",
    "    # 进行合并\n",
    "    calc_cvturn = pd.merge(merge_daily_info,\n",
    "                           calc_factor_data[['Stkcd','TradingDate','alpha_new_factor']],\n",
    "                           on=['Stkcd','TradingDate'],\n",
    "                           how='left')\n",
    "    calc_cvturn = calc_cvturn.rename(columns={'alpha_new_factor': 'alpha032'})\n",
    "except NameError:\n",
    "    print(\"错误：'merge_daily_info' 未定义，请确保该DataFrame存在后再执行合并。\")\n",
    "\n",
    "\n",
    "# 去掉缺失值与inf (根据用户提供的格式)\n",
    "# 这一步会移除 Alpha12_Factor 列中因为 delta 计算导致的 NaN 值 (例如每个股票的第一个交易日)\n",
    "calc_cvturn = calc_cvturn.dropna(subset=['alpha032']) # 只针对因子列去除NaN，避免影响其他数据\n",
    "calc_cvturn = calc_cvturn[~np.isinf(calc_cvturn['alpha032'])] # 确保因子值不是无穷大\n",
    "\n",
    "# 打印结果 DataFrame 的头部，以供检查\n",
    "print(calc_cvturn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7647e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##采用parquet优化内存\n",
    "save_path = r'/Users/xuyanye/Desktop/quant_mm/factor/alpha/alpha032.parquet'\n",
    "calc_cvturn.to_parquet(save_path, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
