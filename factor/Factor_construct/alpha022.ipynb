{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a86776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e4b3e7",
   "metadata": {},
   "source": [
    "### 因子构造样例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897b940d",
   "metadata": {},
   "source": [
    "#### 预先读取merge_daily_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8bdf229",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_daily_info = pd.read_parquet(r'/Users/xuyanye/Desktop/quant mm/factor/data/merge_daily_info.parquet')\n",
    "merge_daily_info['TradingDate'] = pd.to_datetime(merge_daily_info['TradingDate'])\n",
    "merge_daily_info = merge_daily_info.drop_duplicates(subset=['Stkcd','TradingDate'])\n",
    "TRD_Dalyr = pd.read_parquet(r'/Users/xuyanye/Desktop/quant mm/factor/data/TRD_Dalyr.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18295fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Stkcd', 'TradingDate', 'Opnprc', 'Hiprc', 'Loprc', 'Clsprc',\n",
       "       'Dnshrtrd', 'Dnvaltrd', 'Dsmvosd', 'Dsmvtll', 'Dretwd', 'Dretnd',\n",
       "       'Adjprcwd', 'Adjprcnd', 'Markettype', 'Capchgdt', 'Trdsta',\n",
       "       'Ahshrtrd_D', 'Ahvaltrd_D', 'PreClosePrice', 'ChangeRatio', 'LimitDown',\n",
       "       'LimitUp', 'LimitStatus'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRD_Dalyr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30485aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TradingDate', 'Stkcd', 'Hiprc', 'Dnshrtrd', 'Clsprc'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据提取与合并\n",
    "Hiprc = TRD_Dalyr[['TradingDate','Stkcd','Hiprc']]\n",
    "Dnshrtrd = TRD_Dalyr[['TradingDate','Stkcd','Dnshrtrd']]\n",
    "Clsprc = TRD_Dalyr[['TradingDate','Stkcd','Clsprc']]\n",
    "calc_cvturn = pd.merge(Hiprc,Dnshrtrd ,on=['TradingDate','Stkcd'],how='left')\n",
    "calc_cvturn = pd.merge(calc_cvturn,Clsprc ,on=['TradingDate','Stkcd'],how='left')\n",
    "# 现在 calc_factor_data 应该只包含 'TradingDate', 'Stkcd', 'Opnprc', 'Clsprc'\n",
    "calc_cvturn.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c4c8b",
   "metadata": {},
   "source": [
    "# alpha022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ce57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_FACTOR_NAME = \"alpha022\" \n",
    "ALPHA_SAVE_PATH_DIR = \"/Users/xuyanye/Desktop/quant mm/factor/alpha\"\n",
    "if not os.path.exists(ALPHA_SAVE_PATH_DIR):\n",
    "    os.makedirs(ALPHA_SAVE_PATH_DIR)\n",
    "# 定义最终因子在DataFrame中的列名，以及Parquet文件的基础名称\n",
    "# 这两部分必须一致，才能被您的回测代码正确识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42946890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/sy28sk9165s6btqff5dbsdmc0000gn/T/ipykernel_14358/2217402216.py:9: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  calc_factor_data['corr_high_volume_5'] = calc_factor_data.groupby('Stkcd').apply(\n"
     ]
    }
   ],
   "source": [
    "calc_factor_data = calc_cvturn.copy()\n",
    "\n",
    "# 1. 确保数据按股票代码和交易日期排序\n",
    "# 这一步对于计算时间序列相关的函数（如 diff, rolling, shift）至关重要\n",
    "calc_factor_data = calc_factor_data.sort_values(by=['Stkcd', 'TradingDate']).copy()\n",
    "\n",
    "# 2. 计算滚动5日高价和成交股数的关联系数 (correlation)\n",
    "# min_periods=1 允许在数据不足5期时也进行计算\n",
    "calc_factor_data['corr_high_volume_5'] = calc_factor_data.groupby('Stkcd').apply(\n",
    "    lambda x: x['Hiprc'].rolling(window=5, min_periods=1).corr(x['Dnshrtrd'])\n",
    ").reset_index(level=0, drop=True)\n",
    "\n",
    "# 3. 计算5日关联系数的5期差分 (delta)\n",
    "# 这将计算当前5日关联系数与5期前5日关联系数的变化量。如果此值降低（负值），则表明相关性减弱或反向程度增加。\n",
    "calc_factor_data['delta_corr_high_volume_5_5'] = calc_factor_data.groupby('Stkcd')['corr_high_volume_5'].diff(5)\n",
    "\n",
    "# 4. 计算滚动20日收盘价的标准差 (stddev)\n",
    "# min_periods=1 允许在数据不足20期时也进行计算。标准差越大，表示波动性越大。\n",
    "calc_factor_data['stddev_close_20'] = calc_factor_data.groupby('Stkcd')['Clsprc'].rolling(window=20, min_periods=1).std().reset_index(level=0, drop=True)\n",
    "\n",
    "# 5. 对20日收盘价标准差进行跨截面（每天）排名 (rank)\n",
    "# 'method=\"average\"' 是 pandas 默认的排名方式，'ascending=True' 默认是升序排名。排名越大，表示波动性在所有股票中相对越大。\n",
    "calc_factor_data['rank_stddev_close_20'] = calc_factor_data.groupby('TradingDate')['stddev_close_20'].rank(method='average', ascending=True)\n",
    "\n",
    "# 6. 对排名结果进行标准化 (standardization)，这里使用Z-score标准化\n",
    "# 按照每天进行分组，对每个股票的排名进行标准化。标准化确保排名值具有可比性。\n",
    "calc_factor_data['std_rank_stddev_close_20'] = calc_factor_data.groupby('TradingDate')['rank_stddev_close_20'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# 7. 计算因子中间项：delta(correlation(high, volume, 5), 5) * rank(stddev(close,20))\n",
    "# 我们的目标是：\n",
    "#   - 当 delta_corr_high_volume_5_5 降低（负值，表示量价反向程度增加）时，因子倾向于投资。\n",
    "#   - 当 std_rank_stddev_close_20 增加（正值，表示波动率增加）时，因子倾向于投资。\n",
    "# 因此，当 delta_corr_high_volume_5_5 为负且 std_rank_stddev_close_20 为正时，它们的乘积 product_term 将为负。\n",
    "calc_factor_data['product_term'] = calc_factor_data['delta_corr_high_volume_5_5'] * calc_factor_data['std_rank_stddev_close_20']\n",
    "\n",
    "# 8. 计算最终的因子值：-1 * product_term\n",
    "# 由于我们希望当 product_term 为负时（即量价反向程度增加且波动率增加时）因子值变大，所以乘以 -1。\n",
    "# 这样，因子值越大，代表越倾向于投资。\n",
    "calc_factor_data['alpha_new_factor'] = -1 * calc_factor_data['product_term']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11b13da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Stkcd TradingDate  alpha022\n",
      "6       1  1991-04-10  0.491139\n",
      "7       1  1991-04-12  0.031699\n",
      "9       1  1991-04-16  0.329332\n",
      "10      1  1991-04-17  0.411163\n",
      "11      1  1991-04-18  1.315259\n"
     ]
    }
   ],
   "source": [
    "# 假设 merge_daily_info 是另一个包含 Stkcd 和 TradingDate 的 DataFrame\n",
    "# 将计算出的 Alpha08_Factor 合并到 merge_daily_info\n",
    "# 注意：如果 calc_cvturn 就是最终要用的 DataFrame，可能不需要这一步合并\n",
    "# 这里为了与用户提供的格式保持一致，假设有一个目标 DataFrame 'merge_daily_info'\n",
    "# 如果 calc_cvturn 本身就是最终结果，则可以跳过此合并步骤\n",
    "# 请根据实际情况调整 'merge_daily_info' 的定义\n",
    "try:\n",
    "    # 模拟 merge_daily_info 如果它不存在\n",
    "    if 'merge_daily_info' not in locals():\n",
    "        print(\"警告：'merge_daily_info' 未定义。为演示目的，将假设 merge_daily_info 等同于 calc_cvturn 的基础部分。\")\n",
    "        merge_daily_info = calc_cvturn[['Stkcd', 'TradingDate']].copy() # 只是一个示例\n",
    "\n",
    "    # 进行合并\n",
    "    calc_cvturn = pd.merge(merge_daily_info,\n",
    "                           calc_factor_data[['Stkcd','TradingDate','alpha_new_factor']],\n",
    "                           on=['Stkcd','TradingDate'],\n",
    "                           how='left')\n",
    "    calc_cvturn = calc_cvturn.rename(columns={'alpha_new_factor': 'alpha022'})\n",
    "except NameError:\n",
    "    print(\"错误：'merge_daily_info' 未定义，请确保该DataFrame存在后再执行合并。\")\n",
    "\n",
    "\n",
    "# 去掉缺失值与inf (根据用户提供的格式)\n",
    "# 这一步会移除 Alpha12_Factor 列中因为 delta 计算导致的 NaN 值 (例如每个股票的第一个交易日)\n",
    "calc_cvturn = calc_cvturn.dropna(subset=['alpha022']) # 只针对因子列去除NaN，避免影响其他数据\n",
    "calc_cvturn = calc_cvturn[~np.isinf(calc_cvturn['alpha022'])] # 确保因子值不是无穷大\n",
    "\n",
    "# 打印结果 DataFrame 的头部，以供检查\n",
    "print(calc_cvturn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7647e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##采用parquet优化内存\n",
    "save_path = r'/Users/xuyanye/Desktop/quant mm/factor/alpha/alpha022.parquet'\n",
    "calc_cvturn.to_parquet(save_path, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
