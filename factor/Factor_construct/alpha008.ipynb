{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a86776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e4b3e7",
   "metadata": {},
   "source": [
    "### 因子构造样例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897b940d",
   "metadata": {},
   "source": [
    "#### 预先读取merge_daily_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8bdf229",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_daily_info = pd.read_parquet(r'/Users/xuyanye/Desktop/quant mm/factor/data/merge_daily_info.parquet')\n",
    "merge_daily_info['TradingDate'] = pd.to_datetime(merge_daily_info['TradingDate'])\n",
    "merge_daily_info = merge_daily_info.drop_duplicates(subset=['Stkcd','TradingDate'])\n",
    "TRD_Dalyr = pd.read_parquet(r'/Users/xuyanye/Desktop/quant mm/factor/data/TRD_Dalyr.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18295fed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Stkcd', 'TradingDate', 'Opnprc', 'Hiprc', 'Loprc', 'Clsprc',\n",
       "       'Dnshrtrd', 'Dnvaltrd', 'Dsmvosd', 'Dsmvtll', 'Dretwd', 'Dretnd',\n",
       "       'Adjprcwd', 'Adjprcnd', 'Markettype', 'Capchgdt', 'Trdsta',\n",
       "       'Ahshrtrd_D', 'Ahvaltrd_D', 'PreClosePrice', 'ChangeRatio', 'LimitDown',\n",
       "       'LimitUp', 'LimitStatus'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRD_Dalyr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30485aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TradingDate', 'Stkcd', 'Opnprc', 'Clsprc'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据提取与合并\n",
    "Opnprc = TRD_Dalyr[['TradingDate','Stkcd','Opnprc']]\n",
    "Clsprc = TRD_Dalyr[['TradingDate','Stkcd','Clsprc']]\n",
    "calc_cvturn = pd.merge(Opnprc, Clsprc, on=['TradingDate', 'Stkcd'], how='left')\n",
    "# 现在 calc_factor_data 应该只包含 'TradingDate', 'Stkcd', 'Opnprc', 'Clsprc'\n",
    "calc_cvturn.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865c4c8b",
   "metadata": {},
   "source": [
    "# alpha008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57ce57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_FACTOR_NAME = \"alpha008\" \n",
    "ALPHA_SAVE_PATH_DIR = \"/Users/xuyanye/Desktop/quant mm/factor/alpha\"\n",
    "if not os.path.exists(ALPHA_SAVE_PATH_DIR):\n",
    "    os.makedirs(ALPHA_SAVE_PATH_DIR)\n",
    "# 定义最终因子在DataFrame中的列名，以及Parquet文件的基础名称\n",
    "# 这两部分必须一致，才能被您的回测代码正确识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42946890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 因子计算步骤 ---\n",
    "calc_factor_data = calc_cvturn.copy()\n",
    "\n",
    "# 1. 确保数据按股票代码和交易日期排序\n",
    "# 这一步对于计算时间序列相关的函数（如 diff, rolling, shift）至关重要\n",
    "calc_factor_data = calc_factor_data.sort_values(by=['Stkcd', 'TradingDate']).copy()\n",
    "\n",
    "# 2. 计算 daily returns (日收益率)\n",
    "# 基于 Clsprc 列计算\n",
    "calc_factor_data['daily_returns'] = calc_factor_data.groupby('Stkcd')['Clsprc'].pct_change()\n",
    "\n",
    "# 3. 计算 sum(open, 5) - 过去5个交易日的开盘价之和\n",
    "calc_factor_data['sum_open_5'] = calc_factor_data.groupby('Stkcd')['Opnprc'].rolling(window=5, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "\n",
    "# 4. 计算 sum(returns, 5) - 过去5个交易日的日收益率之和\n",
    "calc_factor_data['sum_returns_5'] = calc_factor_data.groupby('Stkcd')['daily_returns'].rolling(window=5, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "\n",
    "# 5. 计算 product_term = (sum(open,5) * sum(returns,5))\n",
    "calc_factor_data['product_term'] = calc_factor_data['sum_open_5'] * calc_factor_data['sum_returns_5']\n",
    "\n",
    "# 6. 计算 delay(product_term, 10) - product_term 10个交易日之前的值\n",
    "calc_factor_data['delay_product_term_10'] = calc_factor_data.groupby('Stkcd')['product_term'].shift(10)\n",
    "\n",
    "# 7. 计算 inner_diff = product_term - delay(product_term, 10)\n",
    "calc_factor_data['inner_diff_term'] = calc_factor_data['product_term'] - calc_factor_data['delay_product_term_10']\n",
    "\n",
    "# 8. 计算 rank(inner_diff) - 对 inner_diff_term 进行跨截面（每天）排名\n",
    "# 'method=\"average\"' 是 pandas 默认的排名方式，'ascending=True' 默认是升序排名\n",
    "calc_factor_data['ranked_inner_diff'] = calc_factor_data.groupby('TradingDate')['inner_diff_term'].rank(method='average', ascending=True)\n",
    "\n",
    "# 9. 对 ranked_inner_diff 进行标准化 (z-score 标准化)\n",
    "calc_factor_data['ranked_inner_diff_standardized'] = calc_factor_data.groupby('TradingDate')['ranked_inner_diff'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "# 10. 计算最终的因子值 (这里我们称之为 alpha_new_factor)\n",
    "# factor = -1 * ranked_inner_diff_standardized\n",
    "calc_factor_data['alpha_new_factor'] = -1 * calc_factor_data['ranked_inner_diff_standardized']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b13da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Stkcd TradingDate  alpha008\n",
      "11      1  1991-04-18 -0.000000\n",
      "12      1  1991-04-19  0.612372\n",
      "14      1  1991-04-23  0.365148\n",
      "15      1  1991-04-24  0.612372\n",
      "16      1  1991-04-25  1.095445\n"
     ]
    }
   ],
   "source": [
    "# 假设 merge_daily_info 是另一个包含 Stkcd 和 TradingDate 的 DataFrame\n",
    "# 将计算出的 Alpha08_Factor 合并到 merge_daily_info\n",
    "# 注意：如果 calc_cvturn 就是最终要用的 DataFrame，可能不需要这一步合并\n",
    "# 这里为了与用户提供的格式保持一致，假设有一个目标 DataFrame 'merge_daily_info'\n",
    "# 如果 calc_cvturn 本身就是最终结果，则可以跳过此合并步骤\n",
    "# 请根据实际情况调整 'merge_daily_info' 的定义\n",
    "try:\n",
    "    # 模拟 merge_daily_info 如果它不存在\n",
    "    if 'merge_daily_info' not in locals():\n",
    "        print(\"警告：'merge_daily_info' 未定义。为演示目的，将假设 merge_daily_info 等同于 calc_cvturn 的基础部分。\")\n",
    "        merge_daily_info = calc_cvturn[['Stkcd', 'TradingDate']].copy() # 只是一个示例\n",
    "\n",
    "    # 进行合并\n",
    "    calc_cvturn = pd.merge(merge_daily_info,\n",
    "                           calc_factor_data[['Stkcd','TradingDate','alpha_new_factor']],\n",
    "                           on=['Stkcd','TradingDate'],\n",
    "                           how='left')\n",
    "    calc_cvturn = calc_cvturn.rename(columns={'alpha_new_factor': 'alpha008'})\n",
    "except NameError:\n",
    "    print(\"错误：'merge_daily_info' 未定义，请确保该DataFrame存在后再执行合并。\")\n",
    "\n",
    "\n",
    "# 去掉缺失值与inf (根据用户提供的格式)\n",
    "# 这一步会移除 Alpha12_Factor 列中因为 delta 计算导致的 NaN 值 (例如每个股票的第一个交易日)\n",
    "calc_cvturn = calc_cvturn.dropna(subset=['alpha008']) # 只针对因子列去除NaN，避免影响其他数据\n",
    "calc_cvturn = calc_cvturn[~np.isinf(calc_cvturn['alpha008'])] # 确保因子值不是无穷大\n",
    "\n",
    "# 打印结果 DataFrame 的头部，以供检查\n",
    "print(calc_cvturn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7647e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##采用parquet优化内存\n",
    "save_path = r'/Users/xuyanye/Desktop/quant mm/factor/alpha/alpha008.parquet'\n",
    "calc_cvturn.to_parquet(save_path, compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
